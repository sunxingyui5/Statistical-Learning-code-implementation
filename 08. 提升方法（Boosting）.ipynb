{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1501931",
   "metadata": {},
   "source": [
    "#### AdaBoost算法：  \n",
    "**输入**：训练数据集$T=\\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N) \\}$，其中$x_i\\in X\\subseteq R^n$，$y_i\\in Y=\\{-1,+1 \\}$；弱学习算法；  \n",
    "**输出**：最总分类器$G(x)$。  \n",
    "（1）初始化训练数据的权值分布  \n",
    "&emsp;&emsp;&emsp;$D_1=(w_{11},...,w_{1i},...,w_{1N})$,&emsp;$w_{1i}=\\frac{1}{N}$,&emsp;$i=1,2,...,N $  \n",
    "（2）对$m=1,2,...,M$  \n",
    "&emsp;（a）使用具有权值分布$D_m$的训练数据集学习，得到基本分类器  \n",
    "&emsp;&emsp;&emsp;$G_m(x):X\\to \\{-1,+1 \\}$  \n",
    "&emsp;（b）计算$G_m(x)$在训练数据集上的分类误差率  \n",
    "&emsp;&emsp;&emsp;$e_m=\\sum_{i=1}^NP(G_m(x_i)\\ne y_i)=\\sum_{i=1}^Nw_{mi}I(G_m(x_i)\\ne y_i)$  \n",
    "&emsp;（c）计算$G_m(x)$的系数  \n",
    "&emsp;&emsp;&emsp;$\\alpha_m=\\frac{1}{2}log\\frac{1-e_m}{e_m}$  \n",
    "&emsp;这里的对数是自然对数。  \n",
    "&emsp;（d）更新训练数据集的权值分布  \n",
    "&emsp;&emsp;&emsp;$D_{m+1}=(w_{m+1,1},...,w_{m+1,i},...,w_{m+1,N})$  \n",
    "&emsp;&emsp;&emsp;$w_{m+1,i}=\\frac{w_{mi}}{Z_m}exp(-\\alpha_my_iG_m(x_i)),i=1,2,....N $  \n",
    "&emsp;这里，$Z_m$是规范因子  \n",
    "&emsp;&emsp;&emsp;$Z_m=\\sum_{i=1}^Nw_{mi}exp(-\\alpha_my_iG_m(x_i))$  \n",
    "&emsp;它使$D_{m+1}$成为一个概率分布。  \n",
    "（3）构建基本分类器的线性组合  \n",
    "&emsp;&emsp;&emsp;$f(x)=\\sum_{m=1}^M\\alpha_mG_m(x)$  \n",
    "&emsp;得到最终分类器  \n",
    "&emsp;&emsp;&emsp;$G(x)=sign(f(x))$  \n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;$=sign(\\sum_{m=1}^M\\alpha_mG_m(x))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45182d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dd9266",
   "metadata": {},
   "source": [
    "#### 加载文件  \n",
    "$param fileName$:要加载的文件路径  \n",
    "*return*: 数据集和标签集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b24d045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(fileName):\n",
    "    dataArr = []\n",
    "    labelArr = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        curLine = line.strip().split(',')\n",
    "        dataArr.append([int(int(num) > 128) for num in curLine[1:]])\n",
    "        if int(curLine[0]) == 0:\n",
    "            labelArr.append(1)\n",
    "        else:\n",
    "            labelArr.append(-1)\n",
    "            \n",
    "    #返回数据集和标记\n",
    "    return dataArr, labelArr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86911cab",
   "metadata": {},
   "source": [
    "#### 创建单层提升树  \n",
    "$param trainDataArr$:训练数据集数组  \n",
    "$param trainLabelArr$: 训练标签集数组  \n",
    "$param D$: 算法8.1中的D  \n",
    "*return*: 创建的单层提升树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7183047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSigleBoostingTree(trainDataArr, trainLabelArr, D):\n",
    "    m, n = np.shape(trainDataArr)\n",
    "    # 单层树的字典\n",
    "    sigleBoostTree = {}\n",
    "    # 初始化分类误差率\n",
    "    sigleBoostTree['e'] = 1\n",
    "    # 对每一个特征进行遍历，寻找用于划分的最合适的特征\n",
    "    for i in range(n):\n",
    "        for div in [-0.5, 0.5, 1.5]:\n",
    "            for rule in ['LisOne', 'HisOne']:\n",
    "                Gx, e = calc_e_Gx(trainDataArr, trainLabelArr, i, div, rule, D)\n",
    "                if e < sigleBoostTree['e']:\n",
    "                    sigleBoostTree['e'] = e\n",
    "                    # 存储最优划分点、划分规则、预测结果、特征索引\n",
    "                    sigleBoostTree['div'] = div\n",
    "                    sigleBoostTree['rule'] = rule\n",
    "                    sigleBoostTree['Gx'] = Gx\n",
    "                    sigleBoostTree['feature'] = i\n",
    "                    \n",
    "    # 返回单层的提升树\n",
    "    return sigleBoostTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9131a702",
   "metadata": {},
   "source": [
    "#### 创建提升树   \n",
    "$param trainDataList$:训练数据集  \n",
    "$param trainLabelList$: 训练测试集  \n",
    "$param treeNum$: 树的层数  \n",
    "*return*: 提升树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5c1a729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBosstingTree(trainDataList, trainLabelList, treeNum = 50):\n",
    "    trainDataArr = np.array(trainDataList)\n",
    "    trainLabelArr = np.array(trainLabelList)\n",
    "    finallpredict = [0] * len(trainLabelArr)\n",
    "    m, n = np.shape(trainDataArr)\n",
    "\n",
    "    D = [1 / m] * m\n",
    "    tree = []\n",
    "    #循环创建提升树\n",
    "    for i in range(treeNum):\n",
    "        curTree = createSigleBoostingTree(trainDataArr, trainLabelArr, D)\n",
    "        alpha = 1/2 * np.log((1 - curTree['e']) / curTree['e'])\n",
    "        Gx = curTree['Gx']\n",
    "        D = np.multiply(D, np.exp(-1 * alpha * np.multiply(trainLabelArr, Gx))) / sum(D)\n",
    "        curTree['alpha'] = alpha\n",
    "        tree.append(curTree)\n",
    "\n",
    "        finallpredict += alpha * Gx\n",
    "        error = sum([1 for i in range(len(trainDataList)) if np.sign(finallpredict[i]) != trainLabelArr[i]])\n",
    "        #计算当前最终误差率\n",
    "        finallError = error / len(trainDataList)\n",
    "        if finallError == 0:\n",
    "            return tree\n",
    "        print('iter:%d:%d, sigle error:%.4f, finall error:%.4f'%(i, treeNum, curTree['e'], finallError ))\n",
    "        \n",
    "    #返回整个提升树\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea634de3",
   "metadata": {},
   "source": [
    "#### 计算分类错误率  \n",
    "$param trainDataArr$:训练数据集数字  \n",
    "$param trainLabelArr$: 训练标签集数组  \n",
    "$param n$: 要操作的特征  \n",
    "$param div$:划分点  \n",
    "$param rule$:正反例标签  \n",
    "$param D$:权值分布D  \n",
    "*return*:预测结果，分类误差率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5c67435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_e_Gx(trainDataArr, trainLabelArr, n, div, rule, D):\n",
    "    e = 0\n",
    "    x = trainDataArr[:, n]\n",
    "    y = trainLabelArr\n",
    "    predict = []\n",
    "\n",
    "    if rule == 'LisOne':\n",
    "        L = 1; H = -1\n",
    "    else:\n",
    "        L = -1; H = 1\n",
    "\n",
    "    #遍历所有样本的特征m\n",
    "    for i in range(trainDataArr.shape[0]):\n",
    "        if x[i] < div:\n",
    "            #如果小于划分点，则预测为L\n",
    "            predict.append(L)\n",
    "            if y[i] != L:\n",
    "                e += D[i]\n",
    "        elif x[i] >= div:\n",
    "            predict.append(H)\n",
    "            if y[i] != H:\n",
    "                e += D[i]\n",
    "    #返回预测结果和分类错误率e\n",
    "    return np.array(predict), e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4260c3",
   "metadata": {},
   "source": [
    "#### 输出单独层预测结果  \n",
    "$param x$: 预测样本  \n",
    "$param div$: 划分点  \n",
    "$param rule$: 划分规则  \n",
    "$param feature$: 进行操作的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b844863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, div, rule, feature):\n",
    "    if rule == 'LisOne':\n",
    "        L = 1; H = -1\n",
    "    else:\n",
    "        L = -1; H = 1\n",
    "\n",
    "    #判断预测结果\n",
    "    if x[feature] < div:\n",
    "        return L\n",
    "    else:\n",
    "        return H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4824333a",
   "metadata": {},
   "source": [
    "#### 测试  \n",
    "$param testDataList$:测试数据集  \n",
    "$param testLabelList$: 测试标签集  \n",
    "$param tree$: 提升树  \n",
    "*return*: 准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e28de7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(testDataList, testLabelList, tree):\n",
    "    errorCnt = 0\n",
    "    #遍历每一个测试样本\n",
    "    for i in range(len(testDataList)):\n",
    "        result = 0\n",
    "        #遍历每层的树\n",
    "        for curTree in tree:\n",
    "            div = curTree['div']\n",
    "            rule = curTree['rule']\n",
    "            feature = curTree['feature']\n",
    "            alpha = curTree['alpha']\n",
    "            result += alpha * predict(testDataList[i], div, rule, feature)\n",
    "        #预测结果取sign值\n",
    "        if np.sign(result) != testLabelList[i]:\n",
    "            errorCnt += 1\n",
    "            \n",
    "    #返回准确率\n",
    "    return 1 - errorCnt / len(testDataList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f143ff69",
   "metadata": {},
   "source": [
    "#### 开始实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32e84cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start init train\n",
      "iter:0:5, sigle error:0.0804, finall error:0.0804\n",
      "iter:1:5, sigle error:0.1448, finall error:0.0804\n",
      "iter:2:5, sigle error:0.1362, finall error:0.0585\n",
      "iter:3:5, sigle error:0.1864, finall error:0.0667\n",
      "iter:4:5, sigle error:0.2249, finall error:0.0474\n",
      "start to test\n",
      "the accuracy is: 0.944\n"
     ]
    }
   ],
   "source": [
    "# 获取训练集\n",
    "trainDataList, trainLabelList = loadData('Mnist/mnist_train.csv')\n",
    "\n",
    "# 获取测试集\n",
    "testDataList, testLabelList = loadData('Mnist/mnist_test.csv')\n",
    "\n",
    "#创建提升树\n",
    "print('start init train')\n",
    "tree = createBosstingTree(trainDataList[:10000], trainLabelList[:10000], 5)\n",
    "\n",
    "#测试\n",
    "print('start to test')\n",
    "accuracy = model_test(testDataList[:1000], testLabelList[:1000], tree)\n",
    "print('the accuracy is:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bbee2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
